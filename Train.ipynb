{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from torch import nn\n",
    "from torch.optim import Adam,RMSprop\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import random\n",
    "from torchvision import models\n",
    "from torch.nn import TripletMarginLoss\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn\n",
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Language of Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tesserocr import PyTessBaseAPI\n",
    "\n",
    "def langdetect(path):\n",
    "    images = ['b.jpg']\n",
    "    images[0] = path\n",
    "    count = 0\n",
    "    count2 = 0\n",
    "    #replace Tesseract path by the path on your pc\n",
    "    \n",
    "    with PyTessBaseAPI(path =r\"C:\\Program Files\\Tesseract-OCR\\tessdata\" ,lang = \"hin\") as api:\n",
    "        for img in images:\n",
    "            api.Init()\n",
    "            api.SetImageFile(img)\n",
    "            # print api.AllWordConfidences()\n",
    "            arr = list(api.AllWordConfidences())\n",
    "            sumarr = sum(arr) / float(max(len(arr),0.0001))\n",
    "\n",
    "\n",
    "    with PyTessBaseAPI(path =r\"C:\\Program Files\\Tesseract-OCR\\tessdata\" ,lang = \"eng\") as api:\n",
    "        for img in images:\n",
    "            api.Init()\n",
    "            api.SetImageFile(img)\n",
    "            # print api.AllWordConfidences()\n",
    "            arr2 = list(api.AllWordConfidences())\n",
    "            sumarr2 = sum(arr2) / float(max(len(arr2),0.0001))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    n = min(len(arr) , len(arr2))\n",
    "    for i in range(0 , n):\n",
    "        if (arr[i] > arr2[i]):\n",
    "            count += 1\n",
    "        elif (arr2[i] > arr[i]):\n",
    "            count2 += 1\n",
    "        \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "    if (count2 > count):\n",
    "            lang = \"English\"\n",
    "            conf = sumarr2\n",
    "            api.Init(lang = 'eng')\n",
    "            api.SetImageFile(images[0])\n",
    "            return(lang,conf)\n",
    "    else:\n",
    "            lang = \"Hindi\"\n",
    "            conf = sumarr\n",
    "            api.Init(lang = 'hin')\n",
    "            api.SetImageFile(images[0])\n",
    "            return (lang,conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list = [] #will be used for the negative in triplet loss\n",
    "for i,author_name in tqdm(enumerate(authors)):\n",
    "    images = os.listdir(os.path.join(path,author_name))\n",
    "    random.shuffle(images)\n",
    "    label = i\n",
    "    for j in images:\n",
    "        path_to_append = os.path.join(path,author_name,j)\n",
    "        if langdetect(path_to_append)[0]!=\"Hindi\" or langdetect(path_to_append)[1]<=1e-2:\n",
    "            for _ in range(10):\n",
    "                images_list.append([path_to_append,label])\n",
    "        else:\n",
    "            images_list.append([path_to_append,label])\n",
    "            \n",
    "#Over Sampling the non hindi images by 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle \n",
    "# with open (\"images_list.pickle\",\"rb\") as file:\n",
    "#     images_list = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47112"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mDataset(Dataset):\n",
    "  def __init__(self,array,transform ):\n",
    "    self.array =array\n",
    "    self.transform = transform\n",
    "    \n",
    "  def __getitem__(self,index):\n",
    "    \n",
    "    \n",
    "        indexlist = self.array[index]\n",
    "        img0 = Image.open(indexlist[0])\n",
    "        \n",
    "        #img0 = img0.convert(\"L\")\n",
    "        img0 = self.transform(img0)\n",
    "        label = indexlist[-1]\n",
    "        \n",
    "        if(len(indexlist)==3):\n",
    "          img1 = Image.open(indexlist[1])\n",
    "          #img1 = img1.convert(\"L\")\n",
    "\n",
    "          img1 = self.transform(img1)\n",
    "          return img0,img1,label\n",
    "        else:\n",
    "          return img0,label\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytraintransform = transforms.Compose([transforms.Resize((256,256)),transforms.CenterCrop(224) ,transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])]\n",
    "                               )\n",
    "myvaltransform = transforms.Compose([transforms.Resize((256,256)),transforms.CenterCrop(224) ,transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])]\n",
    "                               )\n",
    "\n",
    "to_tensor = transforms.Compose([transforms.ToTensor(),\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_ds = mDataset(images_list,transform=mytraintransform)\n",
    "train_dataloader = DataLoader(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img1_name</th>\n",
       "      <th>img2_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70a4ba9a.jpg</td>\n",
       "      <td>58f68a00.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e15b612e.jpg</td>\n",
       "      <td>16ce5df2.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6c64d988.jpg</td>\n",
       "      <td>735d3636.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b74681a6.jpg</td>\n",
       "      <td>cb50496d.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c97aa428.jpg</td>\n",
       "      <td>6f9dc747.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5765</th>\n",
       "      <td>4e7762f7.jpg</td>\n",
       "      <td>2f3d2bce.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5766</th>\n",
       "      <td>c1c49f87.jpg</td>\n",
       "      <td>1072597f.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5767</th>\n",
       "      <td>03e66099.jpg</td>\n",
       "      <td>f877b1b6.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5768</th>\n",
       "      <td>8e056e51.jpg</td>\n",
       "      <td>f68e79a1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5769</th>\n",
       "      <td>acd11d73.jpg</td>\n",
       "      <td>7eae060a.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5770 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         img1_name     img2_name  label\n",
       "0     70a4ba9a.jpg  58f68a00.jpg      1\n",
       "1     e15b612e.jpg  16ce5df2.jpg      0\n",
       "2     6c64d988.jpg  735d3636.jpg      1\n",
       "3     b74681a6.jpg  cb50496d.jpg      0\n",
       "4     c97aa428.jpg  6f9dc747.jpg      1\n",
       "...            ...           ...    ...\n",
       "5765  4e7762f7.jpg  2f3d2bce.jpg      0\n",
       "5766  c1c49f87.jpg  1072597f.jpg      0\n",
       "5767  03e66099.jpg  f877b1b6.jpg      1\n",
       "5768  8e056e51.jpg  f68e79a1.jpg      1\n",
       "5769  acd11d73.jpg  7eae060a.jpg      0\n",
       "\n",
       "[5770 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'dataset/val.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiamesepairwiseDataset(Dataset):\n",
    "  def __init__(self,array,path= None,transform = None):\n",
    "    self.array =array\n",
    "    self.transform = transform\n",
    "    self.path = path\n",
    "    \n",
    "  def __getitem__(self,index):\n",
    "    \n",
    "    indexlist = self.array[index]\n",
    "        \n",
    "    if self.path is None:\n",
    "      img0 = Image.open(indexlist[0])\n",
    "      img0 = img0.convert(\"RGB\")\n",
    "\n",
    "      img1 = Image.open(indexlist[1])\n",
    "      img1 = img1.convert(\"RGB\")\n",
    "\n",
    "\n",
    "      \n",
    "    else:\n",
    "      img0 = Image.open(os.path.join(self.path,indexlist[0]))\n",
    "      img0 = img0.convert(\"RGB\")\n",
    "\n",
    "      img1 = Image.open(os.path.join(self.path,indexlist[1]))\n",
    "      img1 = img1.convert(\"RGB\")\n",
    "\n",
    "    \n",
    "    label = indexlist[2]\n",
    "    \n",
    "    if self.transform is not None:\n",
    "        \n",
    "      img0 = self.transform(img0)\n",
    "      img1 = self.transform(img1)\n",
    "    \n",
    "\n",
    "\n",
    "      \n",
    "      \n",
    "    return img0,img1,label\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SiamesepairwiseDataset(np.array(df),path = r'dataset/val',transform=myvaltransform)\n",
    "val_dataloader = DataLoader(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrainednet = models.mobilenet_v2(weights=\"DEFAULT\")\n",
    "\n",
    "pretrainednet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self,pretrain = pretrainednet):\n",
    "        super(Network,self).__init__()\n",
    "        self.pretrained = pretrain\n",
    "        self.tail = nn.Linear(1000,1352)\n",
    "    def forward(self,*args):\n",
    "        ans = []\n",
    "        for arg in args:\n",
    "            ans.append(self.tail(self.pretrained(arg)))\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()\n",
    "optimiser = Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    Tloss = 0\n",
    "    for i in tqdm(train_dataloader):\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        img,label = i\n",
    "        output = model(img)[0]\n",
    "       \n",
    "        loss = criterion(output,label)\n",
    "        Tloss+= loss.item()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "    print(Tloss/len(images_list))\n",
    "def test():\n",
    "    model.eval() \n",
    "\n",
    "    with torch.no_grad():\n",
    "           \n",
    "            testX = np.zeros(5770)\n",
    "            y_true = np.zeros(5770)\n",
    "        \n",
    "            sumdist = 0\n",
    "            counter = 0\n",
    "            batch_size = 1\n",
    "\n",
    "            for i in tqdm(val_dataloader):\n",
    "                \n",
    "                img0,img1,label = i\n",
    "                \n",
    "                #img0,img1 = img0.cuda(),img1.cuda()\n",
    "                \n",
    "                output1 = model.pretrained(img0)\n",
    "                output2 = model.pretrained(img1)\n",
    "                \n",
    "                diff = output1 - output2\n",
    "                \n",
    "                \n",
    "                dist_sq = torch.sum(torch.pow(diff, 2), 1)\n",
    "                dist = torch.sqrt(dist_sq)\n",
    "                \n",
    "                if(counter+batch_size-1<5770):\n",
    "                    testX[counter:counter+batch_size] = dist.cpu()\n",
    "                    y_true[counter:counter+batch_size]  = label\n",
    "                    counter+=batch_size\n",
    "                else:\n",
    "                    testX[counter:] = dist.cpu()\n",
    "                    y_true[counter:] = label\n",
    "            sns.kdeplot(testX[y_true==1],color = \"blue\",label = \"1\")\n",
    "            sns.kdeplot(testX[y_true==0],color = \"red\",label = \"0\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            return testX,y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47112/47112 [2:31:50<00:00,  5.17it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.658801728614494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5770/5770 [09:42<00:00,  9.90it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    \n",
    "    train()\n",
    "    testX,y_true= test()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"modelmobile.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6145580589254767"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = [1 if i <=0.8 else 0 for i in testX]\n",
    "roc_auc_score(y_true,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
